Tensors
==

- 21.03.17
- Tensorsë€ ë¬´ì—‡ì¼ê¹Œ

---

ì°¸ì¡°
---

Reference : [TensorFlow_Guide][TensorFlow_link] (TensorFlow Guide Link)

[TensorFlow_link]: https://www.tensorflow.org/guide/tensor "TensorFlow_Guide"

---



Introduction to Tensors
--

```python
import tensorflow as tf
import numpy as np
```

Tensors are multi-dimensional arrays with a uniform type (called a `dtype`). You can see all supported `dtypes` at [`tf.dtypes.DType`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType).

If you're familiar with [NumPy](https://numpy.org/devdocs/user/quickstart.html), tensors are (kind of) like `np.arrays`.

All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.



í…ì„œëŠ” ê· ì¼í•œ í˜•ì‹ì˜ ë‹¤ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. (dtypeìœ¼ë¡œ ë¶ˆë¦¼) 
tf.dtypes.DTypeì—ì„œ ì§€ì›ë˜ëŠ” dtypesë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

TensorsëŠ” np.arrays í˜•ì‹ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.

ëª¨ë“  TensorëŠ” íŒŒì´ì¬ì˜ ìˆ«ìë‚˜ ë¬¸ìì²˜ëŸ¼ ë¶ˆë³€í•©ë‹ˆë‹¤. Tensorë¥¼ ì—…ë°ì´íŠ¸ë¥¼ í•˜ëŠ” ìœ ì¼í•œ ë°©ë²•ì€ ìƒˆë¡œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.



Basics
--

Here is a "scalar" or "rank-0" tensor . A scalar contains a single value, and no "axes".

ìŠ¤ì¹¼ë¼ ë˜ëŠ” rank-0 ì¸ í…ì„œ, ìŠ¤ì¹¼ë¼ì—ëŠ” ë‹¨ì¼ ê°’ì´ í¬í•¨ë˜ë©° "ì¶•"ì€ ì—†ë‹¤.

```python
# This will be an int32 tensor by default; see "dtypes" below.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)

-----
tf.Tensor(4, shape=(), dtype=int32)
```



A "vector" or "rank-1" tensor is like a list of values. A vector has one axis:

ë²¡í„° ë˜ëŠ” rank-1ì¸ í…ì„œ, ë²¡í„°ì—ëŠ” ì¶•ì´ í•˜ë‚˜ ìˆë‹¤.

```python
# Let's make this a float tensor.
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)

-----
tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
```



A "matrix" or "rank-2" tensor has two axes:

í–‰ë ¬ ë˜ëŠ” rank-2ì¸ í…ì„œ, í–‰ë ¬ì—ëŠ” ë‘ê°œì˜ ì¶•ì´ ìˆë‹¤.

```python
# If you want to be specific, you can set the dtype (see below) at creation time
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor)

-----
tf.Tensor(
[[1. 2.]
 [3. 4.]
 [5. 6.]], shape=(3, 2), dtype=float16)
```

| ìŠ¤ì¹¼ë¼, ëª¨ì–‘ : `[]`                                          | ë²¡í„°, ëª¨ì–‘ : `[3]`                                           | í–‰ë ¬, ëª¨ì–‘ : `[3, 2]`                                        |
| :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| ![ìŠ¤ì¹¼ë¼, ìˆ«ì 4](https://www.tensorflow.org/guide/images/tensor/scalar.png) | ![ê° ì„¹ì…˜ì— ìˆ«ìê°€ í¬í•¨ ëœ 3 ê°œì˜ ì„¹ì…˜ì´ìˆëŠ” ì¤„ì…ë‹ˆë‹¤.](https://www.tensorflow.org/guide/images/tensor/vector.png) | ![ê° ì…€ì— ìˆ«ìê°€ í¬í•¨ ëœ 3x2 ê·¸ë¦¬ë“œ.](https://www.tensorflow.org/guide/images/tensor/matrix.png) |

rankê°€ [], ì¶•ì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì¸ë“¯.



Tensors may have more axes; here is a tensor with three axes:

í…ì„œëŠ” ë”ë§ì€ ì¶•ì„ ê°€ì§ˆ ìˆ˜ ìˆìœ¼ë©° 3ê°œì˜ ì¶•ì„ ê°€ì§„ í…ì„œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```python
# There can be an arbitrary number of
# axes (sometimes called "dimensions")
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)

-----
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```



There are many ways you might visualize a tensor with more than two axes.

ì¶•ì´ ë‘ê°œ ì´ìƒì¸ í…ì„œë¥¼ ì‹œê°í™” í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆë‹¤.

| A 3-axis tensor, shape: `[3, 2, 5]`                          |                                                              |                                                              |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |                                                              |
| ![img](https://www.tensorflow.org/guide/images/tensor/3-axis_numpy.png) | ![img](https://www.tensorflow.org/guide/images/tensor/3-axis_front.png) | ![img](https://www.tensorflow.org/guide/images/tensor/3-axis_block.png) |



You can convert a tensor to a NumPy array either using `np.array` or the `tensor.numpy` method:

np.arrayë‚˜ tensor.numpyì˜ ë°©ë²•ì„ í†µí•˜ì—¬ íƒ ì„œë¥¼ NumPyì˜ ë°°ì—´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. (ë³€í™˜í•  ìˆ˜ ìˆë‹¤.)

```python
np.array(rank_2_tensor)

-----
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

```python
rank_2_tensor.numpy()

-----
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)

```



Tensors often contain floats and ints, but have many other types, including:

í…ì„œëŠ” ë³´í†µ(ì¢…ì¢…) floatsì™€ intsë¥¼ í¬í•¨í•˜ì§€ë§Œ ë” ë§ì€ íƒ€ì…ë“¤ì„ ê°€ì§€ê³ ìˆë‹¤(ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤).

- complex numbers (ë³µì†Œìˆ˜)
- strings (ë¬¸ìì—´)



The base [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) class requires tensors to be "rectangular"---that is, along each axis, every element is the same size. However, there are specialized types of tensors that can handle different shapes:

ê¸°ë³¸ tf.Tensorí´ë˜ìŠ¤ëŠ” í…ì„œê°€ "ì§ì‚¬ê°í˜•"ì´ì–´ì•¼ í•œë‹¤. ì¦‰ ì´ê²ƒì€ ê° ì¶•ì— ë”°ë¼ì„œ ìš”ì†Œë“¤ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼ í•œë‹¤.
ê·¸ëŸ¬ë‚˜ ë‹¤ì–‘í•œ(ë‹¤ë¥¸?) ëª¨ì–‘ì˜ íƒ€ì…ì„ ì‚¬ìš©(ì¡°ì •)í•  ìˆ˜ ìˆëŠ” íŠ¹ë³„í•œ í…ì„œíƒ€ì…ì´ ìˆë‹¤.

- Ragged tensors (see [RaggedTensor](https://www.tensorflow.org/guide/tensor#ragged_tensors) below)  (ë¹„ì •í˜• í…ì„œ)
- Sparse tensors (see [SparseTensor](https://www.tensorflow.org/guide/tensor#sparse_tensors) below)  (í¬ì†Œ í…ì„œ)



You can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication.

 ë”í•˜ê¸°, ìš”ì†Œë³„ ê³±ì…‰, í–‰ë ¬ê°„ì˜ ê³±ì„ í…ì„œì—ì„œ ê¸°ë³¸ì  ìˆ˜í•™(method)ìœ¼ë¡œ í¬í•¨í•˜ê³  ìˆì–´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2])`

print(tf.add(a, b), "\n")
print(tf.multiply(a, b), "\n")
print(tf.matmul(a, b), "\n")

-----
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32) 
```



```python
print(a + b, "\n") # element-wise addition (ìš”ì†Œê°„ ë”í•˜ê¸°)
print(a * b, "\n") # element-wise multiplication (ìš”ì†Œê°„ ê³±)
print(a @ b, "\n") # matrix multiplication (í–‰ë ¬ ê³±)

-----
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32) 
```

êµ³ì´ addë‚˜ multiply, matmul ê°™ì€ ê²ƒì„ ì•ˆì¨ë„ ê³„ì‚°ì´ ë™ì¼í•˜ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 



Tensors are used in all kinds of operations (ops).

í…ì„œ ëª¨ë“  ì¢…ë¥˜ì˜ ì‘ì—…(ì‘ì „)ì—ì„œ ì‚¬ìš©ëœë‹¤.

```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
# Find the index of the largest value
print(tf.argmax(c))
# Compute the softmax
print(tf.nn.softmax(c))

-----
tf.Tensor(10.0, shape=(), dtype=float32)
tf.Tensor([1 0], shape=(2,), dtype=int64)
tf.Tensor(
[[2.6894143e-01 7.3105854e-01]
 [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
```





About shapes
---

Tensors have shapes. 

- **Shape**: The length (number of elements) of each of the axes of a tensor.

- **ëª¨ì–‘** : í…ì„œì˜ ê° ì¶• ê¸¸ì´ (ìš”ì†Œ ìˆ˜)

  

- **Rank**: Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.

- **ìˆœìœ„** : í…ì„œ ì¶•ì˜ ìˆ˜, ìŠ¤ì¹¼ë¼ëŠ” rank0, ë²¡í„°ëŠ” rank1, í–‰ë ¬ì€ rank2ì´ë‹¤.



- **Axis** or **Dimension**: A particular dimension of a tensor.
- **ì¶•** ë˜ëŠ” **ì°¨ì›** : í…ì„œì˜ íŠ¹ì • ì°¨ì›.



- **Size**: The total number of items in the tensor, the product shape vector.
- **í¬ê¸°** : í•´ë‹¹ ëª¨ì–‘ì˜ ë²¡í„°í˜•ì‹ì˜ í…ì„œì˜ ì´ ê°¯ìˆ˜(í•­ëª© ìˆ˜)



**Note:** Although you may see reference to a "tensor of two dimensions", a rank-2 tensor does not usually describe a 2D space.

2ì°¨ì›ì˜ Tensorì™€ rank2ì˜ Tensorì€ ê°™ì§€ ì•Šë‹¤.
ì¦‰ ì—¬ê¸°ì„œ ë§í•˜ëŠ” ê²ƒì€ rank ì™€ ì°¨ì›ì€ ê°™ì€ ì˜ë¯¸ê°€ ì•„ë‹ˆë‹¤ëŠ” ê²ƒì´ë‹¤.



Tensors and [`tf.TensorShape`](https://www.tensorflow.org/api_docs/python/tf/TensorShape) objects have convenient properties for accessing these:

Tensorì™€ tf.TensorShapeì˜ ê°ì²´ëŠ” ì ‘ê·¼í•˜ê¸° ìœ„í•œ í¸ë¦¬í•œ ì†ì„±ì´ ìˆë‹¤.



```python
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

| A rank-4 tensor, shape: `[3, 2, 4, 5]`                       |                                                              |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| ![A tensor shape is like a vector.](https://www.tensorflow.org/guide/images/tensor/shape.png) | ![A 4-axis tensor](https://www.tensorflow.org/guide/images/tensor/4-axis_block.png) |

```python
print("Type of every element:", rank_4_tensor.dtype)
print("Number of axes:", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())

-----
Type of every element: <dtype: 'float32'>
Number of axes: 4
Shape of tensor: (3, 2, 4, 5)
Elements along axis 0 of tensor: 3
Elements along the last axis of tensor: 5
Total number of elements (3*2*4*5):  120
```



While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.

ì¶•ì€ ì¢…ì¢… ì¸ë±ìŠ¤ë¡œ ì°¸ì¡°ë˜ì§€ë§Œ í•­ìƒ ê°ê°ì˜ ì˜ë¯¸ë¥¼ ì¶”ì í•´ì•¼ í•œë‹¤. (ì•Œì•„ë´ì•¼ í•œë‹¤.) ì¢…ì¢… ì¶•ì€ ì „ì—­ì—ì„œ ë¡œì»¬ë¡œ ì •ë ¬ëœë‹¤. 
ë°°ì¹˜ì¶•ì´ ë¨¼ì €ì˜¤ê³  ê³µê°„ ì°¨ì›ì´ì˜¤ê³  ê° ìœ„ì¹˜ì— ëŒ€í•œ ê¸°ëŠ¥ì´ ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜¨ë‹¤. 
ì´ëŸ° ì‹ìœ¼ë¡œ íŠ¹ì§• ë²¡í„°ëŠ” ì—°ì†ì ì¸ ë©”ëª¨ë¦¬ ì˜ì—­ì„ ë³´ì¸ë‹¤.



| Typical axis order                                           |
| :----------------------------------------------------------- |
| ![Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Features](https://www.tensorflow.org/guide/images/tensor/shape2.png) |





Indexing
--

#### Single-axis indexing

TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and the basic rules for NumPy indexing.

TensorFlowëŠ” ê¸°ë³¸ì ì¸ Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë‚˜ ë¬¸ìì—´ì˜ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì²˜ëŸ¼ ê¸°ë³¸ì ì¸ Python indexing ê·œì¹™ê³¼ NumPyì˜ ê¸°ë³¸ inexing ê·œì¹™ì„ ë”°ë¥¸ë‹¤.



- indexes start at `0` (0ë¶€í„° ì¸ë±ìŠ¤ë¥¼ ì‹œì‘)
- negative indices count backwards from the end (ìŒìˆ˜ ì¸ë±ìŠ¤ëŠ” ë’¤ì—ì„œ ë¶€í„° ê³„ì‚° (-1í•˜ë©´ ë§¨ ëì— ê³„ì‚°ë˜ëŠ” ê²ƒ))
- colons, `:`, are used for slices: `start:stop:step ` " : " ì½œë¡ ì€ ìŠ¬ë¼ì´ìŠ¤ì— ì‚¬ìš©ëœë‹¤.

```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())

-----
[ 0  1  1  2  3  5  8 13 21 34]
```



Indexing with a scalar removes the axis:

ìŠ¤ì¹¼ë¼ë¡œ ì¸ë±ì‹±ì„ í•˜ë©´ ì¶•ì´ ì‚¬ë¼ì§„ë‹¤.

```python
print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())

-----
First: 0
Second: 1
Last: 34
```



Indexing with a `:` slice keeps the axis:

:ì„ ì‚¬ìš©í•œ ìŠ¬ë¼ì´ìŠ¤ë¡œ ì¸ë±ì‹±í•˜ë©´ ì¶•ì´ ìœ ì§€ëœë‹¤.

```python
print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())

-----
Everything: [ 0  1  1  2  3  5  8 13 21 34]
Before 4: [0 1 1 2]
From 4 to the end: [ 3  5  8 13 21 34]
From 2, before 7: [1 2 3 5 8]
Every other item: [ 0  1  3  8 21]
Reversed: [34 21 13  8  5  3  2  1  1  0]
```





Multi-axis indexing
---

Higher rank tensors are indexed by passing multiple indices.

ìƒìœ„ rankì—ì„œëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¥¼ ì „ë‹¬í•˜ì—¬ ì¸ë±ì‹±í•œë‹¤.

The exact same rules as in the single-axis case apply to each axis independently.

ë‹¨ì¼ ì¶•ê³¼ ê°™ì€ ê·œì¹™ìœ¼ë¡œ ê° ì¶•ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ì ìš©ëœë‹¤.

```python
print(rank_2_tensor.numpy())

-----
[[1. 2.]
 [3. 4.]
 [5. 6.]]
```



Passing an integer for each index, the result is a scalar.

ê° ì¸ë±ìŠ¤ì— ì •ìˆ˜ë¥¼ ë”í•˜ë©´ ìŠ¤ì¹¼ë¼ê°€ ë‚˜ì˜¨ë‹¤.

```python
# Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())

-----
4.0
```



You can index using any combination of integers and slices:

ì •ìˆ˜ì™€ ìŠ¬ë¼ì´ìŠ¤ë¥¼ ê°™ì´ ì‚¬ìš©í•´ì„œ ì¸ë±ì‹± í•  ìˆ˜ ìˆë‹¤.

```python
# Get row and column tensors
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")

-----
Second row: [3. 4.]
Second column: [2. 4. 6.]
Last row: [5. 6.]
First item in last column: 2.0
Skip the first row:
[[3. 4.]
 [5. 6.]] 
```



Here is an example with a 3-axis tensor (3ì¶• tensor):

```python
print(rank_3_tensor[:, :, 4])

-----
tf.Tensor(
[[ 4  9]
 [14 19]
 [24 29]], shape=(3, 2), dtype=int32)
```

| Selecting the last feature across all locations in each example in the batch |                                                              |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| ![A 3x2x5 tensor with all the values at the index-4 of the last axis selected.](https://www.tensorflow.org/guide/images/tensor/index1.png) | ![The selected values packed into a 2-axis tensor.](https://www.tensorflow.org/guide/images/tensor/index2.png) |

Read the [tensor slicing guide](https://tensorflow.org/guide/tensor_slicing) to learn how you can apply indexing to manipulate individual elements in your tensors.

tensor slicingì„ í•  ë•Œ ì˜ ëª¨ë¥´ê² ìœ¼ë©´ guideë¥¼ ì½ê³  ì¸ë±ì‹±ì„ ì ìš©í•´ì„œ í…ì„œì˜ ê°œë³„ ìš”ì†Œë¥¼ ì¡°ì‘í•˜ëŠ” ë°©ë²•ì„ ì•Œ ìˆ˜ ìˆë‹¤.





Manipulating Shapes
--

Reshaping a tensor is of great utility.

í…ì„œë¥¼ ì¬êµ¬ì„±(reshaping)í•˜ëŠ” ê²ƒì€ ì¢‹ì€ ë°©ë²•ì´ë‹¤(ìœ ìš©í•˜ë‹¤).

```python
# Shape returns a `TensorShape` object that shows the size along each axis
x = tf.constant([[1], [2], [3]])
print(x.shape)

-----
(3, 1)
```

```python
# You can convert this object into a Python list, too
print(x.shape.as_list())

-----
[3, 1]
```



You can reshape a tensor into a new shape. The [`tf.reshape`](https://www.tensorflow.org/api_docs/python/tf/reshape) operation is fast and cheap as the underlying data does not need to be duplicated.

í…ì„œë¥¼ ìƒˆë¡œìš´ ëª¨ì–‘ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. tf.reshapeëŠ” ë³µì‚¬ê°™ì€ ì‘ì—…ì´ ì—†ì–´ ì‘ì—…ì„ ë¹ ë¥´ê²Œ ëë‚¼ ìˆ˜ ìˆë‹¤.

```python
# You can reshape a tensor to a new shape.
# Note that you're passing in a list
reshaped = tf.reshape(x, [1, 3])

print(x.shape)
print(reshaped.shape)

-----
(3, 1)
(1, 3)
```



The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style "row-major" memory ordering, where incrementing the rightmost index corresponds to a single step in memory.

ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ì—ì„œ ë ˆì´ì•„ì›ƒì„ ìœ ì§€í•˜ê³  ë™ì¼í•œ ë°ì´í„°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ìš”ì²­ëœ ëª¨ì–‘ìœ¼ë¡œ ìƒˆ í…ì„œê°€ ìƒì„±ëœë‹¤.
TensorFlowëŠ” CìŠ¤íƒ€ì¼ "row-major"ë©”ëª¨ë¦¬ ìˆœì„œë¥¼ ì‚¬ìš©í•œë‹¤.
ì—¬ê¸°ì„œ ë§¨ ì˜¤ë¥¸ìª½ ì¸ë±ìŠ¤ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒì€ ë©”ëª¨ë¦¬ì˜ ë‹¨ì¼ ë‹¨ê³„ì— í•´ë‹¨í•œë‹¤. 
(ë­”ì†Œë¦¬ì§€...)

```python
print(rank_3_tensor)

-----
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```



If you flatten a tensor you can see what order it is laid out in memory.

í…ì„œë¥¼ í‰í‰í•˜ê²Œ í•˜ë©´ ë©”ëª¨ë¦¬ì— ë°°ì¹˜ ëœ ìˆœì„œë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.

```python
# A `-1` passed in the `shape` argument says "Whatever fits".
print(tf.reshape(rank_3_tensor, [-1]))

-----
tf.Tensor(
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29], shape=(30,), dtype=int32)
```



Typically the only reasonable use of [`tf.reshape`](https://www.tensorflow.org/api_docs/python/tf/reshape) is to combine or split adjacent axes (or add/remove `1`s).

ì¼ë°˜ì ìœ¼ë¡œ tf.resheapeì˜ ìœ ì¼í•œ í•©ë¦¬ì  ì‚¬ìš©ì€ ì¸ì ‘í•œ ì¶•ì„ ê²°í•©í•˜ê±°ë‚˜ ë¶„ë¦¬(ë¶„í• )í•˜ëŠ” ê²ƒì´ë‹¤.

For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:

ì´ 3 * 2 * 5 ì„¼í„°ì˜ ê²½ìš° ìŠ¬ë¼ì´ìŠ¤ê°€ í˜¼í•©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ (3x2)x5ë‚˜ 3x(2x5) ê°™ì´ ëª¨ì–‘ì„ ë³€ê²½í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì´ë‹¤.

```python
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n")
print(tf.reshape(rank_3_tensor, [3, -1]))

-----
tf.Tensor(
[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]
 [15 16 17 18 19]
 [20 21 22 23 24]
 [25 26 27 28 29]], shape=(6, 5), dtype=int32) 

tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9]
 [10 11 12 13 14 15 16 17 18 19]
 [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)
```

| Some good reshapes.                                          |                                                              |                                                              |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![A 3x2x5 tensor](https://www.tensorflow.org/guide/images/tensor/reshape-before.png) | ![The same data reshaped to (3x2)x5](https://www.tensorflow.org/guide/images/tensor/reshape-good1.png) | ![The same data reshaped to 3x(2x5)](https://www.tensorflow.org/guide/images/tensor/reshape-good2.png) |



Reshaping will "work" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.

reshapingì€ ë™ì¼í•œ ì´ ìš”ìˆ˜ì˜ ìˆ˜ë¥¼ ê°€ì§„ ìƒˆ ëª¨ì–‘ì— ëŒ€í•´ì„œ "ì‘ë™(ì¼)"í•˜ì§€ë§Œ ì¶•ì˜ ìˆœì„œë¥¼ ë”°ë¥´ì§€ ì•Šìœ¼ë©´ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.

Swapping axes in [`tf.reshape`](https://www.tensorflow.org/api_docs/python/tf/reshape) does not work; you need [`tf.transpose`](https://www.tensorflow.org/api_docs/python/tf/transpose) for that.

ì¶• êµì²´ëŠ” tf.reshapeê°€ ì‘ë™í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì¶• êµì²´ë¥¼ í•˜ë ¤ë©´ tf.transposeë¥¼ í•´ì•¼í•œë‹¤.

```python
# Bad examples: don't do this

# You can't reorder axes with reshape.
print(tf.reshape(rank_3_tensor, [2, 3, 5]), "\n") 

# This is a mess
print(tf.reshape(rank_3_tensor, [5, 6]), "\n")

# This doesn't work at all
try:
  tf.reshape(rank_3_tensor, [7, -1])
except Exception as e:
  print(f"{type(e).__name__}: {e}")

-----
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]
  [10 11 12 13 14]]

 [[15 16 17 18 19]
  [20 21 22 23 24]
  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) 

tf.Tensor(
[[ 0  1  2  3  4  5]
 [ 6  7  8  9 10 11]
 [12 13 14 15 16 17]
 [18 19 20 21 22 23]
 [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) 

InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]
```



| Some bad reshapes.                                           |                                                              |                                                              |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![You can't reorder axes, use tf.transpose for that](https://www.tensorflow.org/guide/images/tensor/reshape-bad.png) | ![Anything that mixes the slices of data together is probably wrong.](https://www.tensorflow.org/guide/images/tensor/reshape-bad4.png) | ![The new shape must fit exactly.](https://www.tensorflow.org/guide/images/tensor/reshape-bad2.png) |



You may run across not-fully-specified shapes. Either the shape contains a `None` (an axis-length is unknown) or the whole shape is `None` (the rank of the tensor is unknown).

ì™„ì „íˆ ì§€ì •ë˜ì§€ ì•Šì€ shapeë¥¼ ê°€ë¡œì§ˆëŸ¬ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ëª¨ì–‘ì— ì¶•ì˜ ê¸¸ì´ë¥¼ ëª¨ë¥´ê±°ë‚˜ í…ì„œì˜ rankë¥¼ ëª¨ë¥´ëŠ” Noneì˜ shapeê°€ ë‚˜ì˜¬ ê²ƒì´ë‹¤.



Except for [tf.RaggedTensor](https://www.tensorflow.org/guide/tensor#ragged_tensors), such shapes will only occur in the context of TensorFlow's symbolic, graph-building APIs:

tf.RaggedTensorë¥¼ ì œì™¸í•˜ê³  ì´ëŸ° ëª¨ì–‘ì€ TensorFlowì˜ ìƒì§•ì ì¸ ê·¸ë ˆí”„ì—ì„œë§Œ ë‚˜ì˜¨ë‹¤.

- [tf.function](https://www.tensorflow.org/guide/function)
- The [keras functional API](https://www.tensorflow.org/guide/keras/functional).





More on DTypes
--

To inspect a [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor)'s data type use the [`Tensor.dtype`](https://www.tensorflow.org/api_docs/python/tf/Tensor#dtype) property.

tf.Tensorì˜ ë°ì´í„° íƒ€ì…ì„ ì•Œê³  ì‹¶ë‹¤ë©´ Tensor.dtypeë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.



When creating a [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) from a Python object you may optionally specify the datatype.

tf.Tensor ì—ì„œ Python ê°ì²´ë¥¼ ë§Œë“¤ ë•Œ ì„ íƒì ìœ¼ë¡œ ë°ì´í„° íƒ€ì…ì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤.



If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to [`tf.int32`](https://www.tensorflow.org/api_docs/python/tf#int32) and Python floating point numbers to [`tf.float32`](https://www.tensorflow.org/api_docs/python/tf#float32). Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.

ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°(ì§€ì •í•´ì£¼ì§€ ì•Šì„ ê²½ìš°) TensorFlowëŠ” ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¼ìˆ˜ ìˆëŠ” ë°ì´í„° ìœ í˜•ì„ ì„ íƒí•œë‹¤.
TensorFlowëŠ” Pythonì— ì •ìˆ˜ tf.int32ë‚˜ tf.float32ë¡œ ë³€í™˜í•  ê²ƒì´ë‹¤. ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ NumPyì˜ arrayë¡œ ë³€í™œ í•   ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ê·œì¹™ì„ ì‚¬ìš©í•œë‹¤.



You can cast from type to type.

íƒ€ì…ì—ì„œ íƒ€ì…ìœ¼ë¡œ ìºìŠ¤íŠ¸í•  ìˆ˜ ìˆë‹¤.

```python
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
# Now, cast to an uint8 and lose the decimal precision
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)

-----
tf.Tensor([2 3 4], shape=(3,), dtype=uint8)
```





Broadcasting
--

Broadcasting is a concept borrowed from the [equivalent feature in NumPy](https://numpy.org/doc/stable/user/basics.html). In short, under certain conditions, smaller tensors are "stretched" automatically to fit larger tensors when running combined operations on them.

Broadcastingì´ë€ ë„˜íŒŒì´ì˜ ì¤‘ìš”í•œ ê¸°ëŠ¥ì—ì„œ ë¹Œë ¤ì˜¨(ê°€ì ¸ì˜¨) ê¸°ëŠ¥ì´ë‹¤. ìš”ì•½í•˜ìë©´ íŠ¹ì • ì¡°ì „ì—ì„œ ì‘ì€ í…ì„œëŠ” ê²°í•©ëœ ì—°ì‚°ì„ ì‹¤í–‰í•  ë•Œ í° í…ì„œì— ë§ê²Œ ìë™ìœ¼ë¡œ "í™•ì¥"ëœë‹¤.



The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument.

ê°€ì¥ ê°„ë‹¨í•˜ê³  ì¸ë°˜ì ì¸ ê²½ìš°ëŠ” ìŠ¤ì¹¼ë¼ì— í…ì„œë¥¼ ê³±í•˜ê±°ë‚˜ ë”í•˜ë ¤ê³  í• ë•Œì¸ë°, ì´ ê²½ìš° ìŠ¤ì¹¼ë¼ëŠ” ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ë™ì¼í•œ ëª¨ì–‘(shape)ìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ëœë‹¤. 

```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)

-----
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```



Likewise, axes with length 1 can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.

ë§ˆì°¬ê°€ì§€ë¡œ ê¸¸ì´ê°€ 1ì¸ ì¶•ì€ ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤. ë‘ ì¸ìˆ˜ëŠ” ë™ì¼í•œ í¬ê¸°ë¡œ í™•ì¥ ë˜ì–´ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.



In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. 
Note how the leading 1 is optional: The shape of y is `[4]`.

3x1í–‰ë ¬ì€ ìš”ì†Œë³„ë¡œ 1x4í–‰ë ¬ì„ ê³±í•˜ì—¬ 3x4í–‰ë ¬ì„ ìƒì„±í•œë‹¤.  
ì„ í–‰ 1ì´ ì„ íƒì‚¬í•­ì¸ ë°©ë²•ì„ ì°¸ê³ í•´ë¼, yì˜ ëª¨ì–‘ì€ [4]ì´ë‹¤. (???) 

(3x1ì´ 1x4ê°€ ë˜ì„œ ê·¸ëŸ°ê°€, í–‰ì¸ê°€ ì—´ì¸ê°€ë¥¼ ì˜ ë³´ë¼ëŠ” ë§ì¸ê°€...)

```python
# These are the same computations
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))

-----
tf.Tensor(
[[1]
 [2]
 [3]], shape=(3, 1), dtype=int32) 

tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) 

tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

| A broadcasted add: a `[3, 1]` times a `[1, 4]` gives a `[3,4]` |
| :----------------------------------------------------------- |
| ![Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix](https://www.tensorflow.org/guide/images/tensor/broadcasting.png) |



Here is the same operation without broadcasting:

ë¸Œë¡œë“œ ìºìŠ¤íŒ…ì—†ì´ ì‘ì—…í•˜ëŠ” ë‚´ìš©ì´ë‹¤.

```python
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # Again, operator overloading


-----
tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

í™•ì‹¤íˆ ë¸Œë¡œë“œ ìºìŠ¤íŒ…ì´ í¸ë¦¬í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.



Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.

ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë¸Œë¡œë“œ ìºìŠ¤íŒ… ì‘ì—…ì€ í™•ì¥ ëœ Tensorë¥¼ ë©”ëª¨ë¦¬ì—ì„œ êµ¬í˜„í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì‹œê°„ê³¼ ê³µê°„ì ìœ¼ë¡œ ëª¨ë‘ íš¨ìœ¨ì ì´ë‹¤.



You see what broadcasting looks like using [`tf.broadcast_to`](https://www.tensorflow.org/api_docs/python/tf/broadcast_to).

tf.broadcast_toë¥¼ í†µí•´ ë¸Œë¡œë“œìºìŠ¤íŒ…(ì˜ ëª¨ìŠµ)ì„ ë³¼ ìˆ˜ ìˆë‹¤.

```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))

-----
tf.Tensor(
[[1 2 3]
 [1 2 3]
 [1 2 3]], shape=(3, 3), dtype=int32)
```



Unlike a mathematical op, for example, `broadcast_to` does nothing special to save memory. Here, you are materializing the tensor.

ì˜ˆë¥¼ ë“¤ì–´ ìˆ˜í•™ì  ì—°ì‚°ê³¼ ë‹¤ë¥´ê²Œ broadcast_to ëŠ” ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ëŠ”ë° íŠ¹ë³„í•œ ì‘ì—…ì´ ì—†ë‹¤.
ì—¬ê¸°ì—ì„œ í…ì„œë¥¼ êµ¬ì²´í™” í•˜ê³  ìˆë‹¤(?)



It can get even more complicated. [This section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) of Jake VanderPlas's book *Python Data Science Handbook* shows more broadcasting tricks (again in NumPy).

ê·¸ê²ƒì€ ë” ë³µì¡í•´ ì§ˆ ìˆ˜ ìˆë‹¤. Jake VanderPlasì˜ ì±… *Python Data Science Handbook* ì—ëŠ” ë” ë§ì€ ë¸Œë¡œë“œìºìŠ¤íŒ… ë°©ë²•ì´ ìˆë‹¤.





tf.convert_to_tensor
--

Most ops, like [`tf.matmul`](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) and [`tf.reshape`](https://www.tensorflow.org/api_docs/python/tf/reshape) take arguments of class [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor). However, you'll notice in the above case, Python objects shaped like tensors are accepted.

tf.matmulì´ë‚˜ tf.reshape ê°™ì€ ëŒ€ë¶€ë¶„ì˜ opsëŠ” tf.Tensor í´ë ˆìŠ¤ ì¸ìˆ˜ë¥¼ ë°›ëŠ”ë‹¤. í•˜ì§€ë§Œ ì´ëŸ° ìƒí™©ì¼ ë•Œ í…ì„œ ëª¨ì–‘ì˜ Python ê°ì²´ëŠ” í—ˆìš©ëœë‹¤.



Most, but not all, ops call `convert_to_tensor` on non-tensor arguments. There is a registry of conversions, and most object classes like NumPy's `ndarray`, `TensorShape`, Python lists, and [`tf.Variable`](https://www.tensorflow.org/api_docs/python/tf/Variable) will all convert automatically.

ì „ë¶€ëŠ” ì•„ë‹ˆì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ opsëŠ” convert_to_tensorê°€ ì•„ë‹Œ non-tensor ì¸ìë¥¼ í˜¸ì¶œí•œë‹¤.
ë³€í™˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ ë„˜íŒŒì´ ndarray, TensorShape, Python lists, tf.Variablì™€ ê°™ì€ ëŒ€ë¶€ë¶„ì˜ ê°ì²´ í´ë ˆìŠ¤ëŠ” ìë™ì ìœ¼ë¡œ ë³€í™˜ëœë‹¤.



See [`tf.register_tensor_conversion_function`](https://www.tensorflow.org/api_docs/python/tf/register_tensor_conversion_function) for more details, and if you have your own type you'd like to automatically convert to a tensor.

tf.register_tensor_conversion_functionì— ìì„¸í•œ ë‚´ìš©ì´ ìˆìœ¼ë©° ê°€ì§€ê³  ìˆëŠ” ê²ƒì´ ê³ ìœ í•œ íƒ€ì…ì¼ ê²½ìš° ìë™ìœ¼ë¡œ ë³€í™˜ëœë‹¤.





Ragged Tensors (ë¹„ì •í˜• í…ì„œ)
--

A tensor with variable numbers of elements along some axis is called "ragged". Use `tf.ragged.RaggedTensor` for ragged data.

ì¶•ì„ ë”°ë¼ ê°€ë³€ ê°œìˆ˜ì˜ ìš”ì†Œê°€ ìˆëŠ” í…ì„œë¥¼ "ë¹„ì •í˜•"ì´ë¼ê³  ë¶€ë¥¸ë‹¤.



For example, This cannot be represented as a regular tensor:

ì˜ˆë¥¼ë“¤ì–´ ì´ê±´ ì¼ë°˜ì ì¸ í…ì„œë¼ê³  í•  ìˆ˜ ì—†ë‹¤.

| A [`tf.RaggedTensor`](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor), shape: `[4, None]` |
| :----------------------------------------------------------- |
| ![A 2-axis ragged tensor, each row can have a different length.](https://www.tensorflow.org/guide/images/tensor/ragged.png) |

```python
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]

try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")

-----
ValueError: Can't convert non-rectangular Python sequence to Tensor.
```



Instead create a [`tf.RaggedTensor`](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor) using [`tf.ragged.constant`](https://www.tensorflow.org/api_docs/python/tf/ragged/constant):

ëŒ€ì‹  tf.ragged.constantë¥¼ ì´ìš©í•˜ì—¬ tf.RaggedTensorì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)

-----
<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
```



The shape of a [`tf.RaggedTensor`](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor) will contain some axes with unknown lengths:

tf.RaggedTensorì˜ ëª¨ì–‘ì—ëŠ” ì¶•ì˜ ê¸¸ì´ë¥¼ ì•Œìˆ˜ ì—†ëŠ” ì¶•ì´ í¬í•¨ëœë‹¤. (None)

```python
print(ragged_tensor.shape)

-----
(4, None)
```





String tensors
--

[`tf.string`](https://www.tensorflow.org/api_docs/python/tf#string) is a `dtype`, which is to say you can represent data as strings (variable-length byte arrays) in tensors.

tf.string ì€ dtypeìœ¼ë¡œ, ë°ì´í„°ë¥¼ í…ì„œì—ì„œ ë¬¸ìì—´(ê°€ë³€ê¸¸ì´ì˜ ë°”ì´íŠ¸ ë°°ì—´)ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.



The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. See [`tf.strings`](https://www.tensorflow.org/api_docs/python/tf/strings) for functions to manipulate them.

ë¬¸ìì—´ì€ ì›ì(atomic)ë¡œ Python ë¬¸ìì—´ ì²˜ëŸ¼ ì¸ë±ì‹±ì€ í•  ìˆ˜ ì—†ë‹¤. ë¬¸ìì—´ì˜ ê¸¸ì´ëŠ” í…ì„œì˜ ì¶• ì¤‘ í•˜ë‚˜ê°€ ì•„ë‹ˆë‹¤.
tf.string ì˜ í•¨ìˆ˜ë¥¼ ë³´ê³  manipulate í•´ë¼... (ì¡°ì‘í•˜ë ¤ë©´ ê¸°ëŠ¥ì„ ì°¸ì¡°í•´ë¼?)



Here is a scalar string tensor:

```python
# Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)

-----
tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```

And a vector of strings:

| A vector of strings, shape: `[3,]`                           |
| :----------------------------------------------------------- |
| ![The string length is not one of the tensor's axes.](https://www.tensorflow.org/guide/images/tensor/strings.png) |

```python
# If you have three string tensors of different lengths, this is OK.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# Note that the shape is (3,). The string length is not included.
print(tensor_of_strings)

-----
tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
```



In the above printout the `b` prefix indicates that [`tf.string`](https://www.tensorflow.org/api_docs/python/tf#string) dtype is not a unicode string, but a byte-string. See the [Unicode Tutorial](https://www.tensorflow.org/tutorials/load_data/unicode) for more about working with unicode text in TensorFlow.

ìœ„ì˜ ì¶œë ¥ì— bë¥¼ í¬í•¨í•˜ëŠ” ì´ìœ ëŠ” tf.string dtypeê°€ ìœ ë‹ˆì½”ë“œ ë¬¸ìì—´ì´ ì•„ë‹Œ ë°”ì´íŠ¸ ë¬¸ìì—´ì„ì„ ë‚˜íƒ€ë‚¸ë‹¤.
TensorFlowì—ì„œ ìœ ë‹ˆ ì½”ë“œ í…ìŠ¤íŠ¸ ì‘ì—…ì„ í•˜ë ¤ë©´ Unicode Tutorialì„ ì°¸ì¡°í•˜í•´ì„œ í•˜ë©´ ì¢‹ë‹¤.



If you pass unicode characters they are utf-8 encoded.

ìœ ë‹ˆì½”ë“œ ë¬¸ìë¥¼ ì „ë‹¬í•˜ë©´ utf-8ë¡œ ì¸ì½”ë”©ëœë‹¤.

```python
tf.constant("ğŸ¥³ğŸ‘")

-----
<tf.Tensor: shape=(), dtype=string, numpy=b'\xf0\x9f\xa5\xb3\xf0\x9f\x91\x8d'>
```



Some basic functions with strings can be found in [`tf.strings`](https://www.tensorflow.org/api_docs/python/tf/strings), including [`tf.strings.split`](https://www.tensorflow.org/api_docs/python/tf/strings/split).

tf.strings.splitì„ í¬í•¨í•´ì„œ tf.stringsì—ì„œ ëª‡ê°œì˜ ê¸°ë³¸ì ì¸ í•¨ìˆ˜ë¥¼ ì°¾ì„(ì‚¬ìš©í• ) ìˆ˜ ìˆë‹¤.

```python
# You can use split to split a string into a set of tensors
print(tf.strings.split(scalar_string_tensor, sep=" "))

-----
tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)
```



```python
# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,
# as each string might be split into a different number of parts.
print(tf.strings.split(tensor_of_strings))

-----
<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>
```

| Three strings split, shape: `[3, None]`                      |
| :----------------------------------------------------------- |
| ![Splitting multiple strings returns a tf.RaggedTensor](https://www.tensorflow.org/guide/images/tensor/string-split.png) |



And `tf.string.to_number`:

```python
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))

-----
tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)
```



Although you can't use [`tf.cast`](https://www.tensorflow.org/api_docs/python/tf/cast) to turn a string tensor into numbers, you can convert it into bytes, and then into numbers.

tf.castëŠ” ë¬¸ìì—´ í…ì„œë¥¼ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ ì´ê²ƒì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  ë³€í™˜í•œ ë°”ì´íŠ¸ë¥¼ ìˆ«ìë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤.

```python
byte_strings = tf.strings.bytes_split(tf.constant("Duck"))
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8)
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)

-----
Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)
Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)
```



```python
# Or split it up as unicode and then decode it
unicode_bytes = tf.constant("ã‚¢ãƒ’ãƒ« ğŸ¦†")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)

-----
Unicode bytes: tf.Tensor(b'\xe3\x82\xa2\xe3\x83\x92\xe3\x83\xab \xf0\x9f\xa6\x86', shape=(), dtype=string)

Unicode chars: tf.Tensor([b'\xe3\x82\xa2' b'\xe3\x83\x92' b'\xe3\x83\xab' b' ' b'\xf0\x9f\xa6\x86'], shape=(5,), dtype=string)

Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)
```



The [`tf.string`](https://www.tensorflow.org/api_docs/python/tf#string) dtype is used for all raw bytes data in TensorFlow. The [`tf.io`](https://www.tensorflow.org/api_docs/python/tf/io) module contains functions for converting data to and from bytes, including decoding images and parsing csv.

tf.string dtypeëŠ” í…ì„œë¸”ë¡œìš°ì˜ ëª¨ë“  ë°”ì´íŠ¸ë°ì´í„°ì˜ í–‰ì— ì‚¬ìš©ëœë‹¤. tf.ioëª¨ë“ˆì—ëŠ” ì´ë¯¸ì§€ ë””ì½”ë”© ë° csvêµ¬ë¬¸ ë¶„ì„ì„ í¬í•¨í•˜ì—¬ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ë¡œ ë˜ëŠ” ë°”ì´íŠ¸ì—ì„œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì´ ìˆë‹¤.





Sparse tensors (í¬ì†Œ í…ì„œ)
--

Sometimes, your data is sparse, like a very wide embedding space. TensorFlow supports [`tf.sparse.SparseTensor`](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor) and related operations to store sparse data efficiently.

ë•Œë¡œëŠ” ë§¤ìš° ë„“ì€ ì„ë² ë”© ê³µê°„ì²˜ëŸ¼ ë°ì´í„°ê°€ í¬ì†Œí•  ìˆ˜ ìˆë‹¤. í…ì„œí”Œë¡œìš°ëŠ”  í¬ì†Œë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í¬ì†Œ í…ì„œ ë° ê´€ë ¨ì‘ì—…ì„ ì§€ì›í•˜ëŠ” tf.sparse.SparseTensorê¸°ëŠ¥ì„ ì§€ì›í•œë‹¤.

| A [`tf.SparseTensor`](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor), shape: `[3, 4]` |
| :----------------------------------------------------------- |
| ![An 3x4 grid, with values in only two of the cells.](https://www.tensorflow.org/guide/images/tensor/sparse.png) |

```python
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# You can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))

-----
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
```

-----

