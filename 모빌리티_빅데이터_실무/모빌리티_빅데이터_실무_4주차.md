모빌리티 빅데이터 실무
===

세부정보
---

- 담당 : 최혁두 교수님
- 일시 : 화  14:00 ~ 17:00
- 주 사용 플랫폼 : Flow, Zoom, github.io
- 주차 : 4주차 - 21.03.23

---

참조
---

Reference : [IanLecture][IanLecture_link] (교수님 블로그)

[IanLecture_link]: https://goodgodgd.github.io/ian-lecture/archivers/dt-classifier "IanLecture_Reference"

---

Image Classifiers
===

- 목적 : 오브젝트 디텍터(Object Detector)를 구현하기 위함



Implement Image Classifiers
==

영상 분류 모델을 생성, 학습, 평가 코드 구현을 텐서플로와 파이토치 두 가지 프레임워크에서 배워본다.



2. Pytorch
--



## 2.1. Tensor Operation (##)

파이토치의 `torch.tensor`는 텐서플로의 `tf.Tensor`보다 더 Numpy의 `np.ndarray`를 닮았다.
텐서플로와는 달리 파이토치의 텐서는 Numpy처럼 **mutable**객체라서 텐서의 일부를 수정 할 수 있다.
그 외에 사소한 차이로 일부 함수의 이름이 다르다.

|           Numpy            |       Tensorflow        |          Pytorch           |
| :------------------------: | :---------------------: | :------------------------: |
|       `concatenate`        |        `concat`         |           `cat`            |
|       `expand_dims`        |      `expand_dims`      |        `unsqueeze`         |
|  `tensor[np.newaxis, :]`   | `tensor[tf.newaxis, :]` |     `tensor[None, :]`      |
|        `transpose`         |       `transpose`       |         `movedim`          |
| `sum, mean, min, max, ...` |      `reduce_xxx`       | `sum, mean, min, max, ...` |

그리고 텐서 연산 함수를 쓰는 방법이 약간 다르다.
더하기 연산이라고 하면 `np.add(a, b)`, `tf.add(a, b)` 처럼 `torch.add(a, b)`도 가능하지만 `a.add(b)`도 가능하다.

나머지 사용방법은 아래 링크를 참고하면 좋다.

- https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py



## 2.2. Image Classification

이미지 분류 모델은 아래 링크를 참고하셨지만
텐서플로 모델과 동일하게 구현하였고 코드 구조도 비슷하게 유지하셨다.

- https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py



### a) 코드 구조

텐서플로의 `AdvancedClassifier`와 전반적인 코드 구조는 유지하되 파이토치 스타일에 맞춰 모델 정의 부분만 `TorchClsfModel`라는 다른 클래스로 분리하였다.
유틸리티인 `DurationTime`과 `show_samples`는 위와 동일하다.
파일명은 **`pt_classifier.py`**로 지정하셨다.

```python
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from timeit import default_timer as timer
"""
Common utils
"""
class DurationTime:
    pass

def load_dataset(dataname="cifar10", show_imgs=False):
    pass

def show_samples(images, labels, class_names, grid=(3,4)):
    pass
"""
Classifier
"""
class TorchClsfModel(nn.Module):
    def __init__(self):
        pass

    def forward(self, x):
        pass

class TorchClassifier:
    def __init__(self, model, batch_size=32, val_ratio=0.2):
        pass
    
    def train(self, x, y, epochs):
        pass

    def train_batch(self, x_batch, y_batch):
        pass

    def evaluate(self, x, y_true, verbose=True):
        pass

def torch_classifier():
    (x_train, y_train), (x_test, y_test) = load_dataset("cifar10")
    model = TorchClsfModel()
    clsf = TorchClassifier(model)
    clsf.train(x_train, y_train, 5)
    clsf.evaluate(x_test, y_test)

if __name__ == "__main__":
    torch_classifier()
```



### b) 데이터 불러오기

파이토치에서 데이터를 한 단위씩 꺼내거나 읽는 기능은 `torch.utils.data.Dataset`클래스를 상속한 클래스에서 구현한다.
데이터를 학습에 사용하기 위해서는 batching, shuffling, transform (pre-process), multi-threading 등의 기능이 필요한데 이를 `torch.utils.data.DataLoader`클래스에서 제공한다.
Dataset 상속 클래스로 데이터를 읽고 DataLoader 클래스를 통해 학습데이터를 제공하는 것이다.
자세한 내용은 아래 링크에서 볼 수 있다.

- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html

Dataset과 DataLoader에 대한 자세한 내용은 다음에 다루고 여기서는 파이토치에서 제공하는 데이터셋 모듈을 이용해 데이터를 다운받고 numpy형식의 원본 데이터를 출력한다.

여기서 유의할 점은 **이미지를 transpose를 통해 차원 순서를 바꾼다**는 것이다.
CIFAR-10 데이터는 기본적으로 (channel, height, width)형태의 shape을 가진 channel first형식을 가지고 있다.
텐서플로에서는 (height, width, channel)형태의 channel last형식을 주로 사용하지만
파이토치에서는 (channel, height, width)형태의 channel first형식을 사용한다.
하지만 opencv나 matplotlib등 대부분의 이미지를 다루는 다른 패키지에서 channel last를 쓰기 때문에 일단 **channel first** 형식으로 변환해주기 위해 `np.transpose()`함수를 사용했다.

참고로 텐서플로에서도 channel을 앞에 두는 데이터를 처리할 수 있다.
`tf.keras.layers.Conv2D`클래스를 보면 `data_format`이란 옵션이 있는데
"channel_last" (default) 나  "channel_first"옵션을 넣을 수 있다.
(텐서플로에서도 channel_first를 쓰면 연산이 더 빨리 된다는 얘기가 있다.)

```python
def load_dataset(dataname="cifar10", show_imgs=False):
    if dataname == "cifar10":
        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)
        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)
        class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    else:
        raise ValueError(f"Invalid dataset name: {dataname}")

    # pytorch uses image shape like (batch, channel, height, width)
    x_train = np.transpose(np.array(trainset.data), (0, 3, 1, 2))
    y_train = np.array(trainset.targets)
    x_test = np.transpose(np.array(testset.data), (0, 3, 1, 2))
    y_test = np.array(testset.targets)
    x_train, x_test = x_train / 255.0 * 2. - 1., x_test / 255.0 * 2. - 1.
    print(f"Load {dataname} dataset:", x_train.shape, y_train.shape, x_test.shape, y_test.shape)
    if show_imgs:
        show_samples(trainset.data, trainset.targets, class_names)
    return (x_train, y_train), (x_test, y_test)
```

실행결과는 다음과 같다.

```python
Files already downloaded and verified
Files already downloaded and verified
Load cifar10 dataset: (50000, 3, 32, 32) (50000,) (10000, 3, 32, 32) (10000,)
```



### c) 모델 정의

#### 모델 클래스 선언

파이토치에서 일반적으로 모델을 정의하는 방법은 다음과 같다.

1. `torch.nn.Module`을 상속하는 클래스를 만든다.
2. `__init__(self, ...)`함수에서 (학습 파라미터가 포함된)레이어 객체를 멤버 변수로 미리 선언한다.
3. `forward(self, x)` 함수를 만들어 입력(x)을 받아 출력을 계산하여 리턴한다.

이와 같은 방법으로 아래 클래스를 작성하였다.
레이어 구성은 텐서플로 구현과 동일하다.

```python
class TorchClsfModel(nn.Module):
    def __init__(self):
        super(TorchClsfModel, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, 
                               padding=1, padding_mode='zeros')
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1, padding_mode='zeros')
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 8 * 8, 100)
        self.fc2 = nn.Linear(100, 10)
        self.softmax = nn.Softmax()

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 8 * 8)
        x = F.relu(self.fc1(x))
        x = F.dropout(x)
        x = F.softmax(self.fc2(x), dim=1)
        return x
```



#### `torch.nn.functional`

`forward()` 함수에서 입력에 대한 출력을 계산할 때 `__init__()`에서 미리 선언한 레이어 객체를 사용한다.
학습파라미터(weight)가 있는 레이어는 반드시 멤버 변수로 미리 선언을 해줘야 한다.
ReLU처럼 학습 파라미터가 없는 경우에는 멤버 변수로 선언해도 되고 (`nn.ReLU`클래스) 아니면 위와 같이 `torch.nn.functional`모둘에 들어있는 함수 (`F.relu()`)를 사용해도 된다.

`torch.nn`패키지에 직접 들어있는 레이어들은 객체지향 프로그래밍을 위한 클래스들이고 `torch.nn.functional`모듈의 함수들은 함수형 프로그래밍을 위한 함수들이다.
functional에도 Conv2D가 있지만 weight, bias가 내부 변수가 아니라 외부에서 선언해서 입력인자로 넣어줘야 한다.

학습파라미터나 내부 변수가 있는 경우에는 객체형이 편하고 업는 경우에는 함수형이 편하므로 위와같이 적절히 섞어서 사용하면 된다.
`max pooling`도 학습 파라미터는 없지만 `kernal_size`, `stride`와 같은 고정 파라미터가 있으므로 미리 선언하는게 깔끔하다.

중간에 `x.view()`라는 함수는 reshape기능을 하는데 텐서플로의 `tf.reshape()`은 reshape을 한 새로운 텐서를 주지만 파이토치의 view 함수는 메모리는 그대로 둔 채 메모리를 읽는 배열 구조만 바꾸는 것이다.
차원의 순서를 바꾸지 않고 단순히 차원을 합치거나 나누는 경우에는 view를 쓰는 것이 낫다. 차원의 순서를 바꾸는 데는 tranpose나 permute라는 함수를 쓴다.



#### `Sequential model`

혹은 클래스를 정의하지 않고 텐서플로의 `keras.Sequential`처럼 `nn.Sequential`클래스에 레이어 객체들을 쌓아서 바로 모델을 정의할 수도 있다.

``` python
seq_modules = nn.Sequential(
    flatten,
    layer1,
    nn.ReLU(),
    nn.Linear(20, 10)
)
```

그런데 이렇게 선언한 Sequential 모듈을 '모델'로 써도 되고 '레이어'로 써도 된다.
즉 모듈을 다른 모델의 레이어로 사용해도 된다는 것이다.

`nn.Sequential`도 `nn.Module`을 상속받은 것인데 `nn.Module`의 하위 클래스들은 모두 모델이나 레이어로 사용될 수 있다. 이름자체가 모듈이기 때문에 명시적으로 모델과 레이어를 구분하지 않는다.
`nn.Module`은 단지 특정한 연산 과정을 정의할 뿐이다. 
그래서 `nn.Module`하위 클래스에서 모델을 정의할 때 `nn.Sequential`객체를 레이어처럼 써도 되고 반대로 `nn.Sequential`을 선언할 때 `nn.Module`하위 클래스를 레이어 처럼 써도 된다.

참고로 텐서플로에서도 `tf.keras.Layer`와 `tf.keras.Model`이 기능상 큰 차이는 없다.
보통 레이어를 쌓아서 모델을 만들지만 작은 모델들을 연결하거나 기존 모델 위에 다른 레이어를 추가하여 새로운 모델을 만들 수 있다.
다만 `tf.keras.Model`은 `tf.keras.Layer`클래스를 상속하여 `predict, evaluate`등의 모델 특화 기능을 추가한 것이다.



#### `Mixed model`

`nn.Module`과 `nn.Sequential`을 섞어서 쓰면 다음과 같은 모델 정의 클래스를 만들 수 있다.
conv-pooling-relu 로 반복되는 과정을 하나의 모듈로 선언하여 `forward()`함수가 좀 더 단순해졌다.

```python
class TorchClsfModel(nn.Module):
    def __init__(self):
        super(TorchClsfModel, self).__init__()
        self.conv_relu_pool1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, 
                      padding=1, padding_mode='zeros'),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.ReLU(),
        )
        self.conv_relu_pool2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1, padding_mode='zeros'),
            nn.MaxPool2d(2, 2),
            nn.ReLU(),
        )
        self.fc1 = nn.Linear(64 * 8 * 8, 100)
        self.fc2 = nn.Linear(100, 10)
        self.softmax = nn.Softmax()

    def forward(self, x):
        x = self.conv_relu_pool1(x)
        x = self.conv_relu_pool2(x)
        x = x.view(-1, 64 * 8 * 8)
        x = F.relu(self.fc1(x))
        x = F.dropout(x)
        x = F.softmax(self.fc2(x), dim=1)
        return x
```





### d) 분류기 학습

생성자에서는 학습시킬 모델과 학습과정에 필요한 파라미터와 객체들을 멤버변수로 저장한다.

`train()`에서는 numpy데이터를 `torch.tensor`형식으로 변환하고 train set과 validation set으로 나눈다.
텐서 데이터로 부터 바로 `torch.utils.data.Dataset`객체를 만들기 위해 `torch.utils.data.TensorDataset`함수를 사용한다.
입력데이터의 첫번째 차원을 인덱싱 하여 데이터를 하나씩 꺼내준다.

`torch.utils.data.DataLoader`을 이용해 `vatch_size, shuffle, num_workers`를 설정한다.
`num_workers`는 여러 데이터를 multi - thread 를 통해 읽어들여 데이터 입력속도를 높이는 옵션이다.

```python
class TorchClassifier:
    def __init__(self, model, batch_size=32, val_ratio=0.2):
        self.model = model
        self.loss_object = nn.CrossEntropyLoss()
        self.optimizer = optim.RMSprop(self.model.parameters(), lr=0.001)
        self.batch_size = batch_size
        self.val_ratio = val_ratio

    def train(self, x, y, epochs):
        x, y = torch.from_numpy(x).float(), torch.from_numpy(y)
        trainlen = int(x.shape[0] * (1 - self.val_ratio))
        x_train, y_train = x[:trainlen], y[:trainlen]
        trainset = torch.utils.data.TensorDataset(x_train, y_train)
        trainloader = torch.utils.data.DataLoader(trainset, batch_size=self.batch_size, shuffle=True, num_workers=2)
        x_val, y_val = x[trainlen:], y[trainlen:]

        with DurationTime("** training time"):
            for epoch in range(epochs):
                for x_batch, y_batch in trainloader:
                    self.train_batch(x_batch, y_batch)

                loss, accuracy = self.evaluate(x_val, y_val, verbose=False)
                print(f"[Training] epoch={epoch}, val_loss={loss:1.4f}, val_accuracy={accuracy:1.4f}")
```

실제 학습과정은 `train_batch()`에 나와있다.
먼저 `optimizer.zero_grad()`를 통해 gradient 메모리를 초기화 해야한다.
입력에 대한 모델 출력과 `loss` 계산결과를 바탕으로 학습을 진행한다.

`loss.backward()`는 `loss` 계산 과정의 모든 연산에 대한 gradient를 계산한다.
`optimizer.step()`은 모델의 파라미터를 업데이트 하는데 모델이 입력인자에 없다.
생성자에서 모델 파라미털의 포인터를 이미 `optimizer`에 전달해서 가지고 있기 때문에 학습시에는 입력인자가 없어도 된다.
`loss.backward()`함수에서 만든 모델 파라미터에 대한 gradient 계산 결과는 모델 파라미터 변수 내부에 자체적으로 저장되기 때문에 `loss`와 `optimizer`가 코드상으로 직접 연관이 없어도 파라미터를 통해 gradient가 전잘될 수 있다.

```python
    def train_batch(self, x_batch, y_batch):
        # zero the parameter gradients
        self.optimizer.zero_grad()
        # forward + backward + optimize
        y_pred = self.model(x_batch)
        loss = self.loss_object(y_pred, y_batch)
        loss.backward()
        self.optimizer.step()
```

실행한 결과는 다음과 같다.

``` python
[Training] epoch=0, val_loss=2.0494, val_accuracy=0.4077
[Training] epoch=1, val_loss=1.9923, val_accuracy=0.4628
[Training] epoch=2, val_loss=1.9802, val_accuracy=0.4772
[Training] epoch=3, val_loss=1.9489, val_accuracy=0.5089
[Training] epoch=4, val_loss=1.9408, val_accuracy=0.5177
** training time: 59.81
```



### e) 평가

평가 함수는 텐서플로 모델과 크게 다르지 않다.
numpy데이터와 파이토치의 텐서 데이터 사이의 형변형에 포인트를 두고 봐보자.

- `np.ndarray` > `torch.Tensor` : `torch.from_numpy(x)`
- `torch.Tensor`(GPU device) > `np.ndarray` : `x.detach().numpy()`

`Tensor.detach()`함수는 연산 그래프에서 텐서 데이터를 복사해온다는 것인데 detach한 데이터는 더이상 gradient를 계산할 수 없게 된다.
텐서를 먼저 detach 한 후에야 numpy 데이터로 변환할 수 있다.

```python
    def evaluate(self, x, y_true, verbose=True):
        if isinstance(x, np.ndarray):
            x, y_true = torch.from_numpy(x).float(), torch.from_numpy(y_true)

        y_pred = self.model(x)
        accuracy = torch.mean((torch.argmax(y_pred, dim=1) == y_true).float())
        loss = self.loss_object(y_pred, y_true)
        if verbose:
            np.set_printoptions(precision=4, suppress=True)
            print("  prediction shape:", y_pred.shape, y_true.shape)
            print("  first 5 predicts:\n", y_pred[:5].detach().numpy())
            print("  check probability:", torch.sum(y_pred[:5], dim=1))
            print(f"  loss={loss.detach().numpy():1.4f}, accuracy={accuracy.detach().numpy():1.4f}")
        return loss, accuracy
```

실행한 결과는 다음과 같다.

``` python
  prediction shape: torch.Size([10000, 10]) torch.Size([10000])
  first 5 predicts:
 [[0.     0.     0.0001 0.9454 0.     0.0546 0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     0.     0.001  0.     0.999  0.     0.     0.    ]]
  check probability: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)
  loss=1.9367, accuracy=0.5206
```

결과를 보면 텐서플로에 비해 시간도 오래 걸리고 정확도도 낮은데
워낙 작은 모델이라 이걸로 두 프레임워크를 비교하는 것은 성급하다.

파이토치가 텐서플로에 비해 속도가 비슷하거나 빠르다는 주장도 있어서 일반적으로 쓰이는 좀 더 큰모델에서의 검증이 필요하다.

___

